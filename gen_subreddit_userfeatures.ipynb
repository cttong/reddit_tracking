{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the_donald user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: EOF inside string starting at line 740456",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d1fb126077d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Load Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcol_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'author'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'subreddit'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'created_utc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtd_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/user_histories/td_userhistdata_000000000001'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#td_df = td_df.append(pd.read_csv('./data/user_histories/td_userhistdata_000000000001', dtype = col_types), ignore_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\CharlesTong\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\CharlesTong\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\CharlesTong\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    980\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\CharlesTong\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1717\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1719\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1720\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1721\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas\\_libs\\parsers.c:10862)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas\\_libs\\parsers.c:11138)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas\\_libs\\parsers.c:11884)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows (pandas\\_libs\\parsers.c:11755)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error (pandas\\_libs\\parsers.c:28765)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at line 740456"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "col_types = {'author': str, 'body':str, 'subreddit':str, 'created_utc':int, 'score': int}\n",
    "td_df = pd.read_csv('./data/user_histories/td_userhistdata_000000000001', dtype = col_types)\n",
    "#td_df = td_df.append(pd.read_csv('./data/user_histories/td_userhistdata_000000000001', dtype = col_types), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocess Data\n",
    "td_df = td_df[td_df['subreddit'] == 'The_Donald'] #Filter by relevant subreddit\n",
    "td_df = td_df[(td_df['created_utc'] >= 1454284800) & (td_df['created_utc'] < 1468540800)] #Filter by relevant time frame \n",
    "\n",
    "td_df = td_df.sort_values(['created_utc','author']).reset_index(drop=True) #Sort Data\n",
    "td_df['body'] = td_df['body'].apply(lambda x: str(x)) #fix exceptions [was reading as NaN instead of string]\n",
    "\n",
    "#Replace open parens with space (to account for hyperlink formatting on reddit)\n",
    "td_df['body'] = td_df['body'].apply(lambda x: x.replace(r\"(\",\"  \")) \n",
    "td_df['body'] = td_df['body'].apply(lambda x: x.replace(r\")\",\"  \")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-nyx-</td>\n",
       "      <td>[the, ruling, coalition, already, doesnt, have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0piat3</td>\n",
       "      <td>[do, you, think, the, black, gun, is, scarier,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000Clowns</td>\n",
       "      <td>[if, that, happens, this, republican, since, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000stomachcrunches</td>\n",
       "      <td>[well, yeah, despite, being, the, best, and, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011011</td>\n",
       "      <td>[if, thats, the, case, she, should, be, pullin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11234a3</td>\n",
       "      <td>[yeesh, who, jerks, it, to, 3d, women, anymore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1337and0</td>\n",
       "      <td>[aw, dang, i, shouldve, changed, ricky, to, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>138glv</td>\n",
       "      <td>[god, dam, rekt, we, can, all, agree, induce, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13inchpoop</td>\n",
       "      <td>[women, are, always, the, ones, bitching, abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1875coalminer</td>\n",
       "      <td>[whoa, put, a, nsfw, tag, on, that, too, much,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                               body\n",
       "0                -nyx-  [the, ruling, coalition, already, doesnt, have...\n",
       "1               0piat3  [do, you, think, the, black, gun, is, scarier,...\n",
       "2           1000Clowns  [if, that, happens, this, republican, since, 1...\n",
       "3  1000stomachcrunches  [well, yeah, despite, being, the, best, and, b...\n",
       "4              1011011  [if, thats, the, case, she, should, be, pullin...\n",
       "5              11234a3  [yeesh, who, jerks, it, to, 3d, women, anymore...\n",
       "6             1337and0  [aw, dang, i, shouldve, changed, ricky, to, re...\n",
       "7               138glv  [god, dam, rekt, we, can, all, agree, induce, ...\n",
       "8           13inchpoop  [women, are, always, the, ones, bitching, abou...\n",
       "9        1875coalminer  [whoa, put, a, nsfw, tag, on, that, too, much,..."
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group data s.t. authors/bodies are grouped together\n",
    "td_df = td_df.groupby('author')['body'].apply(lambda x: \"%s\" % ' '.join(x)).reset_index()\n",
    "#This should result in 1 combined string per person (each person posts one \"super post\" made up of all their posts)\n",
    "\n",
    "#Import and utilize a function from Jack's script which roughly sanitizes input strings\n",
    "from fighting_words_py3 import basic_sanitize \n",
    "td_df['body'] = td_df['body'].apply(lambda x: basic_sanitize(x).split()) \n",
    "\n",
    "#Replace all strings which start with \"http\" with a marker for hyperlinks\n",
    "td_df['body'] = td_df['body'].apply(lambda x: [i if i[0:4] != 'http' else '<HYPERLINK>' for i in x])\n",
    "td_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export data\n",
    "td_df.to_csv('./data/language_models/td_preproc_langmodel.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess sandersforpresident language model base data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ThomK</td>\n",
       "      <td>It's interesting to think about the theology b...</td>\n",
       "      <td>funny</td>\n",
       "      <td>1224801481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>superiority</td>\n",
       "      <td>Downmodded for being on the CrimethInc. websit...</td>\n",
       "      <td>pics</td>\n",
       "      <td>1213772343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banjowashisnameo</td>\n",
       "      <td>Ghosts do not have data caps as far as I know</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1447955469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rasheemo</td>\n",
       "      <td>you're welcome &amp;lt;3</td>\n",
       "      <td>humor</td>\n",
       "      <td>1225832208</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rasheemo</td>\n",
       "      <td>this post would have been fine without the unn...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1277522212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IBFT</td>\n",
       "      <td>That's what I'm using.</td>\n",
       "      <td>Nexus5</td>\n",
       "      <td>1431914223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hbgoddard</td>\n",
       "      <td>&amp;gt;zoom in the googles\\n\\n&amp;gt;googles</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>1432432333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>miashaee</td>\n",
       "      <td>No idea as I do not know the full limits of wh...</td>\n",
       "      <td>DebateReligion</td>\n",
       "      <td>1421178891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ArchbishopHamster</td>\n",
       "      <td>This is the kind of quality shit I'm here for.</td>\n",
       "      <td>baseball</td>\n",
       "      <td>1444357974</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mikebyrneyadigg</td>\n",
       "      <td>The man was wounded laying on the ground and t...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>1458909012</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                               body  \\\n",
       "0              ThomK  It's interesting to think about the theology b...   \n",
       "1        superiority  Downmodded for being on the CrimethInc. websit...   \n",
       "2   banjowashisnameo      Ghosts do not have data caps as far as I know   \n",
       "3           rasheemo                               you're welcome &lt;3   \n",
       "4           rasheemo  this post would have been fine without the unn...   \n",
       "5               IBFT                             That's what I'm using.   \n",
       "6          hbgoddard             &gt;zoom in the googles\\n\\n&gt;googles   \n",
       "7           miashaee  No idea as I do not know the full limits of wh...   \n",
       "8  ArchbishopHamster     This is the kind of quality shit I'm here for.   \n",
       "9    Mikebyrneyadigg  The man was wounded laying on the ground and t...   \n",
       "\n",
       "         subreddit  created_utc  score  \n",
       "0            funny   1224801481      0  \n",
       "1             pics   1213772343      0  \n",
       "2   Showerthoughts   1447955469      1  \n",
       "3            humor   1225832208      2  \n",
       "4       reddit.com   1277522212      1  \n",
       "5           Nexus5   1431914223      1  \n",
       "6  leagueoflegends   1432432333      3  \n",
       "7   DebateReligion   1421178891      1  \n",
       "8         baseball   1444357974      4  \n",
       "9        worldnews   1458909012      5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Data\n",
    "sfp_df = pd.read_csv('./data/user_histories/sfp_userhistdata_000000000000', dtype = col_types)\n",
    "#sfp_df = sfp_df.append(pd.read_csv('./data/user_histories/sfp_userhistdata_000000000001', dtype = col_types), ignore_index=True)\n",
    "sfp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crickets</td>\n",
       "      <td>That seems to me to be the inherent flaw with ...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1150350296</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crickets</td>\n",
       "      <td>I suppose I should clarify what I view to be t...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1150417797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crickets</td>\n",
       "      <td>There is an outtake from this interview up on ...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1150842759</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>limukala</td>\n",
       "      <td>Give me a break.  If Israel is really just \"te...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1153237661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>limukala</td>\n",
       "      <td>Think about it dumbass, they ARE the bad guys ...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1153239253</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>limukala</td>\n",
       "      <td>Maybe the messages the children were writing w...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1153242989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>limukala</td>\n",
       "      <td>\"How close do you think people are now to the ...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1153248046</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>limukala</td>\n",
       "      <td>No, Everest in most definitely NOT the highest...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1153248666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>limukala</td>\n",
       "      <td>uh, not to nitpick, but Sardinia is not in Gre...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1153249454</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>limukala</td>\n",
       "      <td>Defacing or altering currency is only illegal ...</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>1153289157</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author                                               body   subreddit  \\\n",
       "0  crickets  That seems to me to be the inherent flaw with ...  reddit.com   \n",
       "1  crickets  I suppose I should clarify what I view to be t...  reddit.com   \n",
       "2  crickets  There is an outtake from this interview up on ...  reddit.com   \n",
       "3  limukala  Give me a break.  If Israel is really just \"te...  reddit.com   \n",
       "4  limukala  Think about it dumbass, they ARE the bad guys ...  reddit.com   \n",
       "5  limukala  Maybe the messages the children were writing w...  reddit.com   \n",
       "6  limukala  \"How close do you think people are now to the ...  reddit.com   \n",
       "7  limukala  No, Everest in most definitely NOT the highest...  reddit.com   \n",
       "8  limukala  uh, not to nitpick, but Sardinia is not in Gre...  reddit.com   \n",
       "9  limukala  Defacing or altering currency is only illegal ...  reddit.com   \n",
       "\n",
       "   created_utc  score  \n",
       "0   1150350296     12  \n",
       "1   1150417797      1  \n",
       "2   1150842759      2  \n",
       "3   1153237661      1  \n",
       "4   1153239253     -1  \n",
       "5   1153242989      0  \n",
       "6   1153248046      3  \n",
       "7   1153248666      2  \n",
       "8   1153249454      7  \n",
       "9   1153289157      2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess Data\n",
    "sfp_df = sfp_df.sort_values(['created_utc','subreddit','author']).reset_index(drop=True) #Sort Data\n",
    "sfp_df['body'] = sfp_df['body'].apply(lambda x: str(x)) #fix exceptions [was reading as NaN instead of string]\n",
    "sfp_df.head(10)\n",
    "\n",
    "\n",
    "#Replace open parens with space (to account for hyperlink formatting on reddit)\n",
    "#sfp_df['body'] = sfp_df['body'].apply(lambda x: x.replace(r\"(\",\"  \")) \n",
    "#sfp_df['body'] = sfp_df['body'].apply(lambda x: x.replace(r\")\",\"  \")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Gaka-</td>\n",
       "      <td>[at, the, start, of, this, election, cycle, sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-GheeButtersnaps-</td>\n",
       "      <td>[better, her, than, the, rest, theyre, all, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-MOPPET-</td>\n",
       "      <td>[i, missed, the, registration, deadline, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-SHMOHAWK-</td>\n",
       "      <td>[yeah, please, fill, me, in, wonder, what, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Tesserex-</td>\n",
       "      <td>[are, there, common, ranges, of, ips, in, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-chia-</td>\n",
       "      <td>[just, common, sense, from, bernie, here, no, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0116316</td>\n",
       "      <td>[i, dont, have, a, choice, my, work, leaves, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0826</td>\n",
       "      <td>[me, too, i, was, starting, to, think, this, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0beatbryce</td>\n",
       "      <td>[ummm, have, you, read, the, comments, people,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0m3r7a</td>\n",
       "      <td>[never, thought, of, making, bernie, in, xcom,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                               body\n",
       "0             -Gaka-  [at, the, start, of, this, election, cycle, sp...\n",
       "1  -GheeButtersnaps-  [better, her, than, the, rest, theyre, all, co...\n",
       "2           -MOPPET-  [i, missed, the, registration, deadline, for, ...\n",
       "3         -SHMOHAWK-  [yeah, please, fill, me, in, wonder, what, the...\n",
       "4         -Tesserex-  [are, there, common, ranges, of, ips, in, the,...\n",
       "5             -chia-  [just, common, sense, from, bernie, here, no, ...\n",
       "6            0116316  [i, dont, have, a, choice, my, work, leaves, c...\n",
       "7               0826  [me, too, i, was, starting, to, think, this, w...\n",
       "8         0beatbryce  [ummm, have, you, read, the, comments, people,...\n",
       "9             0m3r7a  [never, thought, of, making, bernie, in, xcom,..."
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group data s.t. authors/bodies are grouped together\n",
    "sfp_df = sfp_df.groupby('author')['body'].apply(lambda x: \"%s\" % ' '.join(x)).reset_index()\n",
    "#This should result in 1 combined string per person (each person posts one \"super post\" made up of all their posts)\n",
    "\n",
    "#Import and utilize a function from Jack's script which roughly sanitizes input strings\n",
    "from fighting_words_py3 import basic_sanitize \n",
    "sfp_df['body'] = sfp_df['body'].apply(lambda x: basic_sanitize(x).split()) \n",
    "\n",
    "#Replace all strings which start with \"http\" with a marker for hyperlinks\n",
    "sfp_df['body'] = sfp_df['body'].apply(lambda x: [i if i[0:4] != 'http' else '<HYPERLINK>' for i in x])\n",
    "sfp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export data\n",
    "sfp_df.to_csv('./data/language_models/sfp_preproc_langmodel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jesuslordofporn</td>\n",
       "      <td>If that is the case, I wonder if he would make...</td>\n",
       "      <td>SandersForPresident</td>\n",
       "      <td>1454297222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2gurl2gurl</td>\n",
       "      <td>The key through getting legislation through Co...</td>\n",
       "      <td>SandersForPresident</td>\n",
       "      <td>1454302379</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2gurl2gurl</td>\n",
       "      <td>They win because we sit at home unless we are ...</td>\n",
       "      <td>SandersForPresident</td>\n",
       "      <td>1454302485</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jrrl</td>\n",
       "      <td>Or, better, spend those 30 minutes meeting oth...</td>\n",
       "      <td>SandersForPresident</td>\n",
       "      <td>1454305172</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smittyblack</td>\n",
       "      <td>Does he have a guy coming in early for himself...</td>\n",
       "      <td>SandersForPresident</td>\n",
       "      <td>1454306535</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                               body  \\\n",
       "0  Jesuslordofporn  If that is the case, I wonder if he would make...   \n",
       "1       2gurl2gurl  The key through getting legislation through Co...   \n",
       "2       2gurl2gurl  They win because we sit at home unless we are ...   \n",
       "3             jrrl  Or, better, spend those 30 minutes meeting oth...   \n",
       "4      Smittyblack  Does he have a guy coming in early for himself...   \n",
       "\n",
       "             subreddit  created_utc  score  \n",
       "0  SandersForPresident   1454297222      0  \n",
       "1  SandersForPresident   1454302379      5  \n",
       "2  SandersForPresident   1454302485      2  \n",
       "3  SandersForPresident   1454305172     11  \n",
       "4  SandersForPresident   1454306535      6  "
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
